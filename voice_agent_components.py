"""
éŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
render_mini_voice_agent() ã®æ©Ÿèƒ½ã‚’åˆ†å‰²ã—ã¦ä¿å®ˆæ€§ã‚’å‘ä¸Š
"""

import os
import json
import tempfile
import uuid
import requests
import streamlit as st


def initialize_voice_agent():
    """éŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–å‡¦ç†"""
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®åˆæœŸåŒ–
    if "voice_agent_messages" not in st.session_state:
        st.session_state["voice_agent_messages"] = [
            {"role": "system", "content": "ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"}
        ]
    
    # éŒ²éŸ³ãƒœã‚¿ãƒ³ã®ãƒã‚°ä¿®æ­£ï¼šå®Œå…¨ã«ç‹¬ç«‹ã—ãŸçŠ¶æ…‹ç®¡ç†
    if "recorder_session_id" not in st.session_state:
        st.session_state["recorder_session_id"] = str(uuid.uuid4())
    
    if "last_audio_data" not in st.session_state:
        st.session_state["last_audio_data"] = None
        
    if "recorder_reset_needed" not in st.session_state:
        st.session_state["recorder_reset_needed"] = False
    
    # å®‰å®šã—ãŸæ–‡å­—èµ·ã“ã—ä¿å­˜ç”¨ã‚­ãƒ¼
    if "last_transcription" not in st.session_state:
        st.session_state["last_transcription"] = ""


def get_azure_client():
    """Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—ï¼ˆéŸ³å£°èªè­˜ãƒ»TTSå¯¾å¿œï¼‰"""
    try:
        from openai import AzureOpenAI
    except Exception:
        st.warning("openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚'pip install openai' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None, None, None, None, None, None, None
    
    # GPTç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆãƒ¡ã‚¤ãƒ³ã®Azure OpenAI - East US 2ï¼‰
    GPT_API_KEY = os.getenv("AZURE_OPENAI_KEY")
    GPT_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
    GPT_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21")
    
    # éŸ³å£°èªè­˜ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆgpt-4o-mini-transcribeç”¨ï¼‰
    VOICE_API_KEY = os.getenv("AZURE_OPENAI_KEY")
    VOICE_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
    VOICE_API_VERSION = os.getenv("VOICE_AZURE_OPENAI_API_VERSION", "2024-06-01")
    
    # TTSç”¨ã®è¨­å®šï¼ˆREST APIç”¨ï¼‰
    TTS_API_KEY = os.getenv("VOICE_TTS_API_KEY", VOICE_API_KEY)  # æœªè¨­å®šã®å ´åˆã¯VOICE_API_KEYã‚’ä½¿ç”¨
    TTS_ENDPOINT = os.getenv("VOICE_TTS_ENDPOINT", VOICE_ENDPOINT)  # æœªè¨­å®šã®å ´åˆã¯VOICE_ENDPOINTã‚’ä½¿ç”¨
    TTS_API_VERSION = os.getenv("VOICE_TTS_API_VERSION", "2025-03-01-preview")
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ¬ç•ªç’°å¢ƒã§ã¯å‰Šé™¤æ¨å¥¨ï¼‰
    if not GPT_API_KEY or not GPT_ENDPOINT:
        st.error("âŒ GPTç”¨ã®ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
        st.info(f"GPT API Key: {'è¨­å®šæ¸ˆã¿' if GPT_API_KEY else 'æœªè¨­å®š'}")
        st.info(f"GPT Endpoint: {GPT_ENDPOINT if GPT_ENDPOINT else 'æœªè¨­å®š'}")
        return None, None, None, None, None, None, None
    
    if not VOICE_API_KEY or not VOICE_ENDPOINT:
        st.error("âŒ éŸ³å£°èªè­˜ç”¨ã®ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
        st.info(f"Voice API Key: {'è¨­å®šæ¸ˆã¿' if VOICE_API_KEY else 'æœªè¨­å®š'}")
        st.info(f"Voice Endpoint: {VOICE_ENDPOINT if VOICE_ENDPOINT else 'æœªè¨­å®š'}")
        return None, None, None, None, None, None, None
    
    # âš ï¸ æœ«å°¾ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ï¼ˆAzure OpenAI SDKã§ã¯ä¸è¦ï¼‰
    GPT_ENDPOINT = GPT_ENDPOINT.rstrip('/')
    VOICE_ENDPOINT = VOICE_ENDPOINT.rstrip('/')
    TTS_ENDPOINT = TTS_ENDPOINT.rstrip('/') if TTS_ENDPOINT else None
    
    try:
        # GPTç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆEast US 2ï¼‰
        gpt_client = AzureOpenAI(
            api_key=GPT_API_KEY,
            azure_endpoint=GPT_ENDPOINT,
            api_version=GPT_API_VERSION,
        )
        
        # éŸ³å£°èªè­˜ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆgpt-4o-mini-transcribeï¼‰
        voice_client = AzureOpenAI(
            api_key=VOICE_API_KEY,
            azure_endpoint=VOICE_ENDPOINT,
            api_version=VOICE_API_VERSION,
        )
    except Exception as e:
        st.error(f"âŒ Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None, None, None, None, None, None
    
    # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåï¼ˆ.envã‹ã‚‰å–å¾—ï¼‰
    GPT_DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_MODEL", "gpt-5-mini")
    STT_DEPLOYMENT_NAME = os.getenv("VOICE_STT_DEPLOYMENT_NAME", "gpt-4o-mini-transcribe")
    TTS_DEPLOYMENT_NAME = os.getenv("VOICE_TTS_DEPLOYMENT_NAME", "gpt-4o-mini-tts")
    
    # TTSè¨­å®šã‚’è¾æ›¸ã«ã¾ã¨ã‚ã‚‹
    tts_config = {
        "api_key": TTS_API_KEY,
        "endpoint": TTS_ENDPOINT,
        "api_version": TTS_API_VERSION,
        "deployment_name": TTS_DEPLOYMENT_NAME
    }
    
    return gpt_client, voice_client, GPT_DEPLOYMENT_NAME, STT_DEPLOYMENT_NAME, tts_config


def load_json_safe(path: str):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å®‰å…¨ãªèª­ã¿è¾¼ã¿"""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None


def contains_any(text: str, keywords: list[str]) -> bool:
    """ãƒ†ã‚­ã‚¹ãƒˆã«æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    text = text or ""
    return any((k in text) for k in keywords if k)


def build_rag_context(query: str) -> str:
    """RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰ï¼ˆé–¢é€£ã™ã‚‹JSONãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼‰"""
    base = os.path.dirname(__file__)
    subjects = load_json_safe(os.path.join(base, "subjects.json"))
    grades = load_json_safe(os.path.join(base, "grades.json"))
    progress = load_json_safe(os.path.join(base, "progress.json"))
    reminders = load_json_safe(os.path.join(base, "reminders.json"))
    
    q = query or ""
    subjects_in_query = []
    if isinstance(subjects, list):
        for s in subjects:
            if isinstance(s, str) and s and s in q:
                subjects_in_query.append(s)
    
    parts: list[str] = []
    
    # å¸¸ã«ç§‘ç›®ä¸€è¦§ã¯ä»˜ä¸ï¼ˆçŸ­ã„ã®ã§ãƒãƒƒãƒ”ãƒ³ã‚°ã«å½¹ç«‹ã¤ï¼‰
    if subjects is not None:
        parts.append("[subjects]\n" + json.dumps(subjects, ensure_ascii=False, indent=2))
    
    # æˆç¸¾
    if isinstance(grades, dict):
        pick = {}
        if subjects_in_query:
            for s in subjects_in_query:
                if s in grades and isinstance(grades[s], list):
                    pick[s] = grades[s][-5:]
        else:
            # å„ç§‘ç›®ã®æœ€æ–°3ä»¶
            for s, arr in grades.items():
                if isinstance(arr, list):
                    pick[s] = arr[-3:]
        if pick:
            parts.append("[grades] (æœ€æ–°)\n" + json.dumps(pick, ensure_ascii=False, indent=2))
    
    # é€²æ—
    if isinstance(progress, dict):
        pick = {}
        if subjects_in_query:
            for s in subjects_in_query:
                if s in progress and isinstance(progress[s], list):
                    pick[s] = progress[s][-5:]
        else:
            for s, arr in progress.items():
                if isinstance(arr, list):
                    pick[s] = arr[-3:]
        if pick and contains_any(q, ["é€²æ—", "æ™‚é–“", "å­¦ç¿’", "ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "progress", "study"]):
            parts.append("[progress] (æœ€æ–°)\n" + json.dumps(pick, ensure_ascii=False, indent=2))
    
    # ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼
    if isinstance(reminders, list):
        pick = reminders
        if subjects_in_query:
            pick = [r for r in reminders if isinstance(r, dict) and r.get("subject") in subjects_in_query]
        if pick and contains_any(q, ["äºˆå®š", "ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼", "ç· åˆ‡", "è©¦é¨“", "reminder", "deadline", "exam"]):
            parts.append("[reminders]\n" + json.dumps(pick, ensure_ascii=False, indent=2))
    
    # é•·ã™ãã‚‹å ´åˆã¯å…ˆé ­ã‚’å„ªå…ˆã—ã¦ã‚«ãƒƒãƒˆ
    ctx = "\n\n".join(parts)
    max_chars = 8000
    if len(ctx) > max_chars:
        ctx = ctx[:max_chars] + "\n... (truncated)"
    return ctx


def handle_voice_input(client, STT_DEPLOYMENT_NAME):
    """éŸ³å£°å…¥åŠ›ã®å‡¦ç†"""
    try:
        from audio_recorder_streamlit import audio_recorder
    except Exception:
        st.warning("audio_recorder_streamlit ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚'pip install audio-recorder-streamlit' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return ""
    
    # éŸ³å£°éŒ²éŸ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
    try:
        audio_bytes = audio_recorder(
            text="ğŸ¤ éŒ²éŸ³",
            recording_color="#ff4444",
            neutral_color="#6aa36f",
            icon_name="microphone",
            icon_size="1x",
            key=f"audio_recorder_{st.session_state['recorder_session_id']}"
        )
    except Exception as e:
        st.error(f"éŸ³å£°éŒ²éŸ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return ""
    
    # éŸ³å£°èªè­˜å‡¦ç†ï¼ˆæ”¹è‰¯ç‰ˆ - è¤‡æ•°å½¢å¼å¯¾å¿œï¼‰
    transcribed_text = ""
    
    if audio_bytes and audio_bytes != st.session_state["last_audio_data"]:
        st.session_state["last_audio_data"] = audio_bytes
        
        with st.spinner("éŸ³å£°èªè­˜ä¸­â€¦"):
            tmp_path = None
            try:
                # audio-recorder-streamlitã¯WAVå½¢å¼ã§éŒ²éŸ³ã™ã‚‹ãŸã‚ã€WAVã‚’æœ€å„ªå…ˆ
                formats_to_try = [
                    (".wav", "audio/wav"),
                    (".webm", "audio/webm"),
                    (".mp3", "audio/mpeg"),
                    (".m4a", "audio/mp4"),
                ]
                
                last_error = None
                for suffix, mime_type in formats_to_try:
                    try:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                            tmp.write(audio_bytes)
                            tmp_path = tmp.name
                        
                        with open(tmp_path, "rb") as f:
                            transcription = client.audio.transcriptions.create(
                                model=STT_DEPLOYMENT_NAME,
                                file=(f"audio{suffix}", f, mime_type),
                                response_format="text",
                            )
                        
                        # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                        transcribed_text = transcription if isinstance(transcription, str) else str(transcription)
                        st.success("âœ… éŸ³å£°èªè­˜å®Œäº†ï¼å†…å®¹ã‚’ç¢ºèªã—ã¦é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")
                        break
                        
                    except Exception as e:
                        last_error = e
                        # æœ€åˆã®å½¢å¼ï¼ˆWAVï¼‰ã§å¤±æ•—ã—ãŸå ´åˆã®ã¿è­¦å‘Šã‚’è¡¨ç¤º
                        if suffix == ".wav":
                            st.info("ğŸ”„ åˆ¥ã®å½¢å¼ã§è©¦è¡Œä¸­...")
                        if tmp_path and os.path.exists(tmp_path):
                            try:
                                os.remove(tmp_path)
                            except Exception:
                                pass
                        tmp_path = None
                        continue
                
                # ã™ã¹ã¦ã®å½¢å¼ã§å¤±æ•—ã—ãŸå ´åˆ
                if not transcribed_text and last_error:
                    raise last_error
                
                # éŒ²éŸ³å®Œäº†å¾Œã«è‡ªå‹•ãƒªã‚»ãƒƒãƒˆï¼ˆæ–°ã—ã„éŒ²éŸ³ã®ãŸã‚ã«ï¼‰
                if transcribed_text:
                    st.session_state["recorder_session_id"] = str(uuid.uuid4())
                    st.session_state["last_audio_data"] = None
                    st.session_state["last_transcription"] = transcribed_text
                
            except Exception as e:
                st.error(f"âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
                st.warning("ğŸ’¡ è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :")
                st.write("1. éŒ²éŸ³æ™‚é–“ãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæœ€ä½1ç§’ä»¥ä¸ŠéŒ²éŸ³ã—ã¦ãã ã•ã„ï¼‰")
                st.write("2. ãƒã‚¤ã‚¯ã®æ¨©é™ãŒè¨±å¯ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                st.write("3. éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒç ´æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                st.write(f"4. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå: `{STT_DEPLOYMENT_NAME}`")
                st.write("5. Azure Portalã§ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã¨APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                
                # ãƒ‡ãƒãƒƒã‚°ç”¨: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­ãƒã‚¤ãƒˆã‚’è¡¨ç¤º
                if audio_bytes and len(audio_bytes) > 0:
                    st.write(f"ğŸ” éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­: {audio_bytes[:20].hex()}")
                    
            finally:
                if tmp_path and os.path.exists(tmp_path):
                    try:
                        os.remove(tmp_path)
                    except Exception:
                        pass
    
    return transcribed_text


def generate_speech(text: str, tts_config: dict, voice: str = "alloy") -> bytes:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆï¼ˆREST APIä½¿ç”¨ï¼‰
    
    Args:
        text: éŸ³å£°åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        tts_config: TTSè¨­å®šã®è¾æ›¸ï¼ˆapi_key, endpoint, api_version, deployment_nameï¼‰
        voice: ä½¿ç”¨ã™ã‚‹éŸ³å£°ï¼ˆalloy, echo, fable, onyx, nova, shimmerï¼‰
    
    Returns:
        bytes: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆMP3å½¢å¼ï¼‰ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
    """
    if not text or not text.strip():
        return None
    
    # TTSè¨­å®šã®å–å¾—
    api_key = tts_config.get("api_key")
    endpoint = tts_config.get("endpoint")
    api_version = tts_config.get("api_version")
    deployment_name = tts_config.get("deployment_name")
    
    if not all([api_key, endpoint, deployment_name]):
        st.warning("âš ï¸ TTSè¨­å®šãŒä¸å®Œå…¨ã§ã™ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None
    
    # REST APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURL
    url = f"{endpoint}/openai/deployments/{deployment_name}/audio/speech?api-version={api_version}"
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
    payload = {
        "model": deployment_name,
        "input": text[:4096],  # æœ€å¤§4096æ–‡å­—ã¾ã§
        "voice": voice
    }
    
    try:
        # REST APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            return response.content
        else:
            st.error(f"âŒ TTS APIã‚¨ãƒ©ãƒ¼: {response.status_code}")
            st.error(f"è©³ç´°: {response.text}")
            return None
            
    except requests.exceptions.Timeout:
        st.error("âŒ TTS API ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: 30ç§’ä»¥å†…ã«å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"âŒ TTS API ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ TTS äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def render_input_ui():
    """å…¥åŠ›UIã®è¡¨ç¤ºï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ï¼‰"""
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¯ session_state ã«ä¿æŒã—ã¦ä¸Šæ›¸ãã‚’é˜²ã
        text_key = f"text_input_{st.session_state['recorder_session_id']}"
        if text_key not in st.session_state:
            st.session_state[text_key] = ""
        user_text = st.text_input(
            "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›",
            placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›â€¦",
            key=text_key
        )
        return user_text
    
    return ""


def handle_text_input(user_text: str, transcribed_text: str) -> str:
    """æœ€çµ‚çš„ãªå…¥åŠ›ã®æ±ºå®š"""
    final_input = user_text
    
    # éŸ³å£°èªè­˜çµæœãŒã‚ã‚‹å ´åˆã¯ç·¨é›†å¯èƒ½ãªãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã‚’è¡¨ç¤º
    if st.session_state.get("last_transcription", "") != "":
        st.text_area(
            "èªè­˜çµæœï¼ˆç·¨é›†å¯ï¼‰",
            height=80,
            key="last_transcription"
        )
        final_input = st.session_state.get("last_transcription", "")
    
    return final_input


def render_send_button():
    """é€ä¿¡UIã®è¡¨ç¤º"""
    c1, c2 = st.columns([1, 4])
    
    with c1:
        send = st.button(
            "é€ä¿¡", 
            use_container_width=True,
            key=f"send_button_{st.session_state['recorder_session_id']}"
        )
    
    with c2:
        # éŒ²éŸ³ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if st.button("ğŸ”„ éŒ²éŸ³ãƒªã‚»ãƒƒãƒˆ", help="éŒ²éŸ³ãƒœã‚¿ãƒ³ãŒæ¶ˆãˆãŸæ™‚ã«ä½¿ç”¨"):
            st.session_state["recorder_session_id"] = str(uuid.uuid4())
            st.session_state["last_audio_data"] = None
            st.session_state["recorder_reset_needed"] = False
            st.session_state["last_transcription"] = ""
            st.rerun()
    
    return send


def generate_ai_response(client, GPT_DEPLOYMENT_NAME, final_input: str, tts_config: dict = None):
    """AIå¿œç­”ã®ç”Ÿæˆã¨TTSéŸ³å£°ç”Ÿæˆ"""
    # RAG: ç¾åœ¨ã®è³ªå•ã«é–¢é€£ã™ã‚‹JSONã‚’æ³¨å…¥
    rag_ctx = build_rag_context(final_input)
    rag_system = {
        "role": "system",
        "content": (
            "ä»¥ä¸‹ã¯å‚è€ƒç”¨ã®ãƒ­ãƒ¼ã‚«ãƒ«JSONãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚ã“ã‚Œã‚’æœ€å„ªå…ˆã§å‚ç…§ã—ã€"
            "äº‹å®Ÿã«åŸºã¥ãç°¡æ½”ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„ã“ã¨ã¯æ¨æ¸¬ã›ãšã€"
            "ä¸æ˜ãªç‚¹ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã¯ä¸æ˜ã€ã¨è¿°ã¹ã¦ãã ã•ã„ã€‚\n\n" + rag_ctx
        ),
    }
    
    # é€ä¿¡ç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå…ˆé ­ã® system ã®ç›´å¾Œã« RAG ã‚’æŒ¿å…¥ï¼‰
    base_msgs = st.session_state["voice_agent_messages"]
    if base_msgs and base_msgs[0].get("role") == "system":
        messages_to_send = [base_msgs[0], rag_system] + base_msgs[1:]
    else:
        messages_to_send = [rag_system] + base_msgs
    
    ai_reply = None
    audio_data = None
    
    with st.spinner("ğŸ¤– å¿œç­”ç”Ÿæˆä¸­â€¦"):
        try:
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
            st.info(f"ğŸ” ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {GPT_DEPLOYMENT_NAME}")
            st.info(f"ğŸ” GPT API ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {os.getenv('AZURE_OPENAI_API_VERSION', 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ')}")
            st.info(f"ğŸ” GPT ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {os.getenv('AZURE_OPENAI_ENDPOINT', 'æœªè¨­å®š')}")
            
            resp = client.chat.completions.create(
                model=GPT_DEPLOYMENT_NAME,
                messages=messages_to_send,
                max_completion_tokens=1000,  # GPT-5æ¨è«–ãƒ¢ãƒ‡ãƒ«ç”¨
                # temperature ã¯æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤1ã‚’ä½¿ç”¨ï¼‰
            )
            ai_reply = resp.choices[0].message.content
            
            # TTSéŸ³å£°ç”Ÿæˆ
            if ai_reply and tts_config:
                with st.spinner("ğŸ”Š éŸ³å£°ç”Ÿæˆä¸­..."):
                    audio_data = generate_speech(ai_reply, tts_config)
                    if audio_data:
                        st.success("âœ… éŸ³å£°ç”Ÿæˆå®Œäº†ï¼")
                    
        except Exception as e:
            st.error(f"å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            st.warning("ğŸ’¡ è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :")
            st.write("1. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåãŒæ­£ã—ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            st.write("2. APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¯¾å¿œã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            st.write("3. APIã‚­ãƒ¼ã®æ¨©é™ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            st.write(f"4. ä½¿ç”¨ã—ã‚ˆã†ã¨ã—ãŸãƒ¢ãƒ‡ãƒ«: `{GPT_DEPLOYMENT_NAME}`")
    
    return ai_reply, audio_data


def display_chat_history():
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º"""
    if st.session_state["voice_agent_messages"]:
        st.divider()
        st.caption("ğŸ“ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
        for i, m in enumerate(st.session_state["voice_agent_messages"][-6:]):  # æœ€æ–°6ä»¶ã®ã¿è¡¨ç¤º
            if m["role"] == "user":
                st.markdown(f"**ğŸ‘¤ ã‚ãªãŸ:** {m['content']}")
            elif m["role"] == "assistant":
                st.markdown(f"**ğŸ¤– AI:** {m['content']}")


def render_audio_player(audio_data: bytes):
    """
    éŸ³å£°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®è¡¨ç¤º
    
    Args:
        audio_data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆMP3å½¢å¼ã®ãƒã‚¤ãƒˆåˆ—ï¼‰
    """
    if audio_data:
        st.divider()
        st.caption("ğŸ”Š éŸ³å£°å†ç”Ÿ")
        st.audio(audio_data, format="audio/mp3")
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        st.download_button(
            label="ğŸ“¥ éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=audio_data,
            file_name=f"ai_response_{uuid.uuid4().hex[:8]}.mp3",
            mime="audio/mp3"
        )
