"""
éŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
render_mini_voice_agent() ã®æ©Ÿèƒ½ã‚’åˆ†å‰²ã—ã¦ä¿å®ˆæ€§ã‚’å‘ä¸Š
"""

import os
import json
import tempfile
import time
import uuid
import streamlit as st


def initialize_voice_agent():
    """éŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–å‡¦ç†"""
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®åˆæœŸåŒ–
    if "voice_agent_messages" not in st.session_state:
        st.session_state["voice_agent_messages"] = [
            {"role": "system", "content": "ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"}
        ]
    
    # éŒ²éŸ³ãƒœã‚¿ãƒ³ã®ãƒã‚°ä¿®æ­£ï¼šå®Œå…¨ã«ç‹¬ç«‹ã—ãŸçŠ¶æ…‹ç®¡ç†
    if "recorder_session_id" not in st.session_state:
        st.session_state["recorder_session_id"] = str(uuid.uuid4())
    
    if "last_audio_data" not in st.session_state:
        st.session_state["last_audio_data"] = None
        
    if "recorder_reset_needed" not in st.session_state:
        st.session_state["recorder_reset_needed"] = False
    
    # å®‰å®šã—ãŸæ–‡å­—èµ·ã“ã—ä¿å­˜ç”¨ã‚­ãƒ¼
    if "last_transcription" not in st.session_state:
        st.session_state["last_transcription"] = ""


def get_azure_client():
    """Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—ï¼ˆè¤‡æ•°ãƒªã‚½ãƒ¼ã‚¹å¯¾å¿œï¼‰"""
    try:
        from openai import AzureOpenAI
    except Exception:
        st.warning("openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚'pip install openai' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None, None, None, None, None
    
    # GPTç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆãƒ¡ã‚¤ãƒ³ã®Azure OpenAI - East US 2ï¼‰
    GPT_API_KEY = os.getenv("AZURE_OPENAI_KEY")
    GPT_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
    GPT_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21")
    
    # éŸ³å£°ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚¹ã‚¦ã‚§ãƒ¼ãƒ‡ãƒ³ã®Azure OpenAIï¼‰
    VOICE_API_KEY = os.getenv("VOICE_AZURE_OPENAI_KEY")
    VOICE_ENDPOINT = os.getenv("VOICE_AZURE_OPENAI_ENDPOINT")
    VOICE_API_VERSION = os.getenv("VOICE_AZURE_OPENAI_API_VERSION", "2024-06-01")
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ¬ç•ªç’°å¢ƒã§ã¯å‰Šé™¤æ¨å¥¨ï¼‰
    if not GPT_API_KEY or not GPT_ENDPOINT:
        st.error("âŒ GPTç”¨ã®ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
        st.info(f"GPT API Key: {'è¨­å®šæ¸ˆã¿' if GPT_API_KEY else 'æœªè¨­å®š'}")
        st.info(f"GPT Endpoint: {GPT_ENDPOINT if GPT_ENDPOINT else 'æœªè¨­å®š'}")
        return None, None, None, None, None
    
    if not VOICE_API_KEY or not VOICE_ENDPOINT:
        st.error("âŒ éŸ³å£°ç”¨ã®ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
        st.info(f"Voice API Key: {'è¨­å®šæ¸ˆã¿' if VOICE_API_KEY else 'æœªè¨­å®š'}")
        st.info(f"Voice Endpoint: {VOICE_ENDPOINT if VOICE_ENDPOINT else 'æœªè¨­å®š'}")
        return None, None, None, None, None
    
    # âš ï¸ æœ«å°¾ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ï¼ˆAzure OpenAI SDKã§ã¯ä¸è¦ï¼‰
    GPT_ENDPOINT = GPT_ENDPOINT.rstrip('/')
    VOICE_ENDPOINT = VOICE_ENDPOINT.rstrip('/')
    
    try:
        # GPTç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆEast US 2ï¼‰
        gpt_client = AzureOpenAI(
            api_key=GPT_API_KEY,
            azure_endpoint=GPT_ENDPOINT,
            api_version=GPT_API_VERSION,
        )
        
        # éŸ³å£°ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚¹ã‚¦ã‚§ãƒ¼ãƒ‡ãƒ³ï¼‰
        voice_client = AzureOpenAI(
            api_key=VOICE_API_KEY,
            azure_endpoint=VOICE_ENDPOINT,
            api_version=VOICE_API_VERSION,
        )
    except Exception as e:
        st.error(f"âŒ Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None, None, None, None
    
    # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåï¼ˆ.envã‹ã‚‰å–å¾—ï¼‰
    GPT_DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_MODEL", "gpt-5-mini")
    TTS_DEPLOYMENT_NAME = os.getenv("VOICE_TTS_DEPLOYMENT_NAME", "tts")
    STT_DEPLOYMENT_NAME = os.getenv("VOICE_STT_DEPLOYMENT_NAME", "whisper")
    
    return gpt_client, voice_client, GPT_DEPLOYMENT_NAME, TTS_DEPLOYMENT_NAME, STT_DEPLOYMENT_NAME


def load_json_safe(path: str):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å®‰å…¨ãªèª­ã¿è¾¼ã¿"""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None


def contains_any(text: str, keywords: list[str]) -> bool:
    """ãƒ†ã‚­ã‚¹ãƒˆã«æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    text = text or ""
    return any((k in text) for k in keywords if k)


def build_rag_context(query: str) -> str:
    """RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰ï¼ˆé–¢é€£ã™ã‚‹JSONãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼‰"""
    base = os.path.dirname(__file__)
    subjects = load_json_safe(os.path.join(base, "subjects.json"))
    grades = load_json_safe(os.path.join(base, "grades.json"))
    progress = load_json_safe(os.path.join(base, "progress.json"))
    reminders = load_json_safe(os.path.join(base, "reminders.json"))
    
    q = query or ""
    subjects_in_query = []
    if isinstance(subjects, list):
        for s in subjects:
            if isinstance(s, str) and s and s in q:
                subjects_in_query.append(s)
    
    parts: list[str] = []
    
    # å¸¸ã«ç§‘ç›®ä¸€è¦§ã¯ä»˜ä¸ï¼ˆçŸ­ã„ã®ã§ãƒãƒƒãƒ”ãƒ³ã‚°ã«å½¹ç«‹ã¤ï¼‰
    if subjects is not None:
        parts.append("[subjects]\n" + json.dumps(subjects, ensure_ascii=False, indent=2))
    
    # æˆç¸¾
    if isinstance(grades, dict):
        pick = {}
        if subjects_in_query:
            for s in subjects_in_query:
                if s in grades and isinstance(grades[s], list):
                    pick[s] = grades[s][-5:]
        else:
            # å„ç§‘ç›®ã®æœ€æ–°3ä»¶
            for s, arr in grades.items():
                if isinstance(arr, list):
                    pick[s] = arr[-3:]
        if pick:
            parts.append("[grades] (æœ€æ–°)\n" + json.dumps(pick, ensure_ascii=False, indent=2))
    
    # é€²æ—
    if isinstance(progress, dict):
        pick = {}
        if subjects_in_query:
            for s in subjects_in_query:
                if s in progress and isinstance(progress[s], list):
                    pick[s] = progress[s][-5:]
        else:
            for s, arr in progress.items():
                if isinstance(arr, list):
                    pick[s] = arr[-3:]
        if pick and contains_any(q, ["é€²æ—", "æ™‚é–“", "å­¦ç¿’", "ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "progress", "study"]):
            parts.append("[progress] (æœ€æ–°)\n" + json.dumps(pick, ensure_ascii=False, indent=2))
    
    # ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼
    if isinstance(reminders, list):
        pick = reminders
        if subjects_in_query:
            pick = [r for r in reminders if isinstance(r, dict) and r.get("subject") in subjects_in_query]
        if pick and contains_any(q, ["äºˆå®š", "ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼", "ç· åˆ‡", "è©¦é¨“", "reminder", "deadline", "exam"]):
            parts.append("[reminders]\n" + json.dumps(pick, ensure_ascii=False, indent=2))
    
    # é•·ã™ãã‚‹å ´åˆã¯å…ˆé ­ã‚’å„ªå…ˆã—ã¦ã‚«ãƒƒãƒˆ
    ctx = "\n\n".join(parts)
    max_chars = 8000
    if len(ctx) > max_chars:
        ctx = ctx[:max_chars] + "\n... (truncated)"
    return ctx


def handle_voice_input(client, STT_DEPLOYMENT_NAME):
    """éŸ³å£°å…¥åŠ›ã®å‡¦ç†"""
    try:
        from audio_recorder_streamlit import audio_recorder
    except Exception:
        st.warning("audio_recorder_streamlit ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚'pip install audio-recorder-streamlit' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return ""
    
    # éŸ³å£°éŒ²éŸ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
    try:
        audio_bytes = audio_recorder(
            text="ğŸ¤ éŒ²éŸ³",
            recording_color="#ff4444",
            neutral_color="#6aa36f",
            icon_name="microphone",
            icon_size="1x",
            key=f"audio_recorder_{st.session_state['recorder_session_id']}"
        )
    except Exception as e:
        st.error(f"éŸ³å£°éŒ²éŸ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return ""
    
    # éŸ³å£°èªè­˜å‡¦ç†ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    transcribed_text = ""
    
    if audio_bytes and audio_bytes != st.session_state["last_audio_data"]:
        st.session_state["last_audio_data"] = audio_bytes
        
        with st.spinner("éŸ³å£°èªè­˜ä¸­â€¦"):
            tmp_path = None
            try:
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                st.info(f"ğŸ” Whisper ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå: {STT_DEPLOYMENT_NAME}")
                st.info(f"ğŸ” Whisper ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {os.getenv('VOICE_AZURE_OPENAI_ENDPOINT', 'æœªè¨­å®š')}")
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    tmp.write(audio_bytes)
                    tmp_path = tmp.name
                
                with open(tmp_path, "rb") as f:
                    transcription = client.audio.transcriptions.create(
                        model=STT_DEPLOYMENT_NAME,
                        file=f,
                        response_format="text",
                    )
                
                transcribed_text = transcription if isinstance(transcription, str) else str(transcription)
                st.success("âœ… éŸ³å£°èªè­˜å®Œäº†ï¼å†…å®¹ã‚’ç¢ºèªã—ã¦é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")
                
                # éŒ²éŸ³å®Œäº†å¾Œã«è‡ªå‹•ãƒªã‚»ãƒƒãƒˆï¼ˆæ–°ã—ã„éŒ²éŸ³ã®ãŸã‚ã«ï¼‰
                st.session_state["recorder_session_id"] = str(uuid.uuid4())
                st.session_state["last_audio_data"] = None
                st.session_state["last_transcription"] = transcribed_text
                
            except Exception as e:
                st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
                st.write(f"ğŸ’¡ Whisperãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå: `{STT_DEPLOYMENT_NAME}`")
                st.write("ğŸ’¡ Azure Portalã§ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            finally:
                if tmp_path and os.path.exists(tmp_path):
                    try:
                        os.remove(tmp_path)
                    except Exception:
                        pass
    
    return transcribed_text


def render_input_ui():
    """å…¥åŠ›UIã®è¡¨ç¤ºï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ï¼‰"""
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¯ session_state ã«ä¿æŒã—ã¦ä¸Šæ›¸ãã‚’é˜²ã
        text_key = f"text_input_{st.session_state['recorder_session_id']}"
        if text_key not in st.session_state:
            st.session_state[text_key] = ""
        user_text = st.text_input(
            "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›",
            placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›â€¦",
            key=text_key
        )
        return user_text
    
    return ""


def handle_text_input(user_text: str, transcribed_text: str) -> str:
    """æœ€çµ‚çš„ãªå…¥åŠ›ã®æ±ºå®š"""
    final_input = user_text
    
    # éŸ³å£°èªè­˜çµæœãŒã‚ã‚‹å ´åˆã¯ç·¨é›†å¯èƒ½ãªãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã‚’è¡¨ç¤º
    if st.session_state.get("last_transcription", "") != "":
        st.text_area(
            "èªè­˜çµæœï¼ˆç·¨é›†å¯ï¼‰",
            height=80,
            key="last_transcription"
        )
        final_input = st.session_state.get("last_transcription", "")
    
    return final_input


def render_send_button():
    """é€ä¿¡UIã®è¡¨ç¤º"""
    c1, c2, c3 = st.columns([1, 1, 4])
    
    with c1:
        do_tts = st.checkbox(
            "èª­ã¿ä¸Šã’", 
            value=True,
            key=f"tts_checkbox_{st.session_state['recorder_session_id']}"
        )
    
    with c2:
        send = st.button(
            "é€ä¿¡", 
            use_container_width=True,
            key=f"send_button_{st.session_state['recorder_session_id']}"
        )
    
    with c3:
        # éŒ²éŸ³ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if st.button("ğŸ”„ éŒ²éŸ³ãƒªã‚»ãƒƒãƒˆ", help="éŒ²éŸ³ãƒœã‚¿ãƒ³ãŒæ¶ˆãˆãŸæ™‚ã«ä½¿ç”¨"):
            st.session_state["recorder_session_id"] = str(uuid.uuid4())
            st.session_state["last_audio_data"] = None
            st.session_state["recorder_reset_needed"] = False
            st.session_state["last_transcription"] = ""
            st.rerun()
    
    return send, do_tts


def generate_ai_response(client, GPT_DEPLOYMENT_NAME, final_input: str):
    """AIå¿œç­”ã®ç”Ÿæˆ"""
    # RAG: ç¾åœ¨ã®è³ªå•ã«é–¢é€£ã™ã‚‹JSONã‚’æ³¨å…¥
    rag_ctx = build_rag_context(final_input)
    rag_system = {
        "role": "system",
        "content": (
            "ä»¥ä¸‹ã¯å‚è€ƒç”¨ã®ãƒ­ãƒ¼ã‚«ãƒ«JSONãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚ã“ã‚Œã‚’æœ€å„ªå…ˆã§å‚ç…§ã—ã€"
            "äº‹å®Ÿã«åŸºã¥ãç°¡æ½”ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„ã“ã¨ã¯æ¨æ¸¬ã›ãšã€"
            "ä¸æ˜ãªç‚¹ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã¯ä¸æ˜ã€ã¨è¿°ã¹ã¦ãã ã•ã„ã€‚\n\n" + rag_ctx
        ),
    }
    
    # é€ä¿¡ç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå…ˆé ­ã® system ã®ç›´å¾Œã« RAG ã‚’æŒ¿å…¥ï¼‰
    base_msgs = st.session_state["voice_agent_messages"]
    if base_msgs and base_msgs[0].get("role") == "system":
        messages_to_send = [base_msgs[0], rag_system] + base_msgs[1:]
    else:
        messages_to_send = [rag_system] + base_msgs
    
    ai_reply = None
    with st.spinner("ğŸ¤– å¿œç­”ç”Ÿæˆä¸­â€¦"):
        try:
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
            st.info(f"ğŸ” ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {GPT_DEPLOYMENT_NAME}")
            st.info(f"ğŸ” GPT API ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {os.getenv('AZURE_OPENAI_API_VERSION', 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ')}")
            st.info(f"ğŸ” GPT ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {os.getenv('AZURE_OPENAI_ENDPOINT', 'æœªè¨­å®š')}")
            
            resp = client.chat.completions.create(
                model=GPT_DEPLOYMENT_NAME,
                messages=messages_to_send,
                max_completion_tokens=1000,  # GPT-5æ¨è«–ãƒ¢ãƒ‡ãƒ«ç”¨
                # temperature ã¯æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤1ã‚’ä½¿ç”¨ï¼‰
            )
            ai_reply = resp.choices[0].message.content
        except Exception as e:
            st.error(f"å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            st.warning("ğŸ’¡ è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :")
            st.write("1. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåãŒæ­£ã—ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            st.write("2. APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¯¾å¿œã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            st.write("3. APIã‚­ãƒ¼ã®æ¨©é™ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            st.write(f"4. ä½¿ç”¨ã—ã‚ˆã†ã¨ã—ãŸãƒ¢ãƒ‡ãƒ«: `{GPT_DEPLOYMENT_NAME}`")
    
    return ai_reply


def handle_tts(client, TTS_DEPLOYMENT_NAME, ai_reply: str):
    """TTSï¼ˆãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ï¼‰å‡¦ç†"""
    try:
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
        st.info(f"ğŸ” TTS ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå: {TTS_DEPLOYMENT_NAME}")
        st.info(f"ğŸ” TTS API ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {os.getenv('VOICE_AZURE_OPENAI_API_VERSION', 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ')}")
        st.info(f"ğŸ” TTS ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {os.getenv('VOICE_AZURE_OPENAI_ENDPOINT', 'æœªè¨­å®š')}")
        
        with st.spinner("ğŸ”Š éŸ³å£°åˆæˆä¸­â€¦"):
            speech = client.audio.speech.create(
                model=TTS_DEPLOYMENT_NAME,
                voice="alloy",
                input=ai_reply,
            )
            # ä¸€æ„ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨
            out_path = f"voice_output_{int(time.time())}_{uuid.uuid4().hex[:8]}.mp3"
            with open(out_path, "wb") as f:
                f.write(speech.content)
            with open(out_path, "rb") as f:
                st.audio(f.read(), format="audio/mp3")
            try:
                os.remove(out_path)
            except Exception:
                pass
    except Exception as e:
        st.warning(f"ğŸ”‡ éŸ³å£°åˆæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ: {e}")
        st.error("ğŸ’¡ è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :")
        st.write(f"1. TTSãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå: `{TTS_DEPLOYMENT_NAME}`")
        st.write(f"2. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: `{os.getenv('VOICE_AZURE_OPENAI_ENDPOINT', 'æœªè¨­å®š')}`")
        st.write(f"3. APIãƒãƒ¼ã‚¸ãƒ§ãƒ³: `{os.getenv('VOICE_AZURE_OPENAI_API_VERSION', 'æœªè¨­å®š')}`")
        st.write("4. Azure Portalã§ä¸Šè¨˜ã®è¨­å®šãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„")


def display_chat_history():
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º"""
    if st.session_state["voice_agent_messages"]:
        st.divider()
        st.caption("ğŸ“ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
        for i, m in enumerate(st.session_state["voice_agent_messages"][-6:]):  # æœ€æ–°6ä»¶ã®ã¿è¡¨ç¤º
            if m["role"] == "user":
                st.markdown(f"**ğŸ‘¤ ã‚ãªãŸ:** {m['content']}")
            elif m["role"] == "assistant":
                st.markdown(f"**ğŸ¤– AI:** {m['content']}")
